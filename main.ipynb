{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-15T20:59:33.412313600Z",
     "start_time": "2023-11-15T20:59:30.494891300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import re\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datasets import concatenate_datasets, load_dataset_builder, get_dataset_config_names, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Bias Frames is a new way of representing the biases and offensiveness that are implied in language.\n",
      "For example, these frames are meant to distill the implication that \"women (candidates) are less qualified\"\n",
      "behind the statement \"we shouldnâ€™t lower our standards to hire more women.\"\n",
      "['default']\n"
     ]
    }
   ],
   "source": [
    "# Load Social Bias Frames dataset\n",
    "ds_builder = load_dataset_builder(\"social_bias_frames\")\n",
    "print(ds_builder.info.description)\n",
    "configs = get_dataset_config_names(\"social_bias_frames\")\n",
    "print(configs)\n",
    "\n",
    "# train\n",
    "train_data = load_dataset(\"social_bias_frames\", split=\"train\")\n",
    "# test\n",
    "test_data = load_dataset(\"social_bias_frames\", split=\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T20:59:41.419464400Z",
     "start_time": "2023-11-15T20:59:33.411314200Z"
    }
   },
   "id": "99b41e3ead5fd2a2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Check if links and emojis in text\n",
    "def has_links(text):\n",
    "    # Define a regular expression for URLs\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    return int(bool(re.search(url_pattern, text)))\n",
    "\n",
    "\n",
    "def has_emojis(text):\n",
    "    # Define a regular expression for emojis\n",
    "    emoji_pattern = r'[\\U00010000-\\U0010ffff]'\n",
    "    return int(bool(re.search(emoji_pattern, text)))\n",
    "\n",
    "\n",
    "# Apply the custom functions to the dataset\n",
    "def apply_custom_features(dataset):\n",
    "    dataset = dataset.map(lambda x: {\"HasLinksYN\": 'Y' if has_links(x['post']) else 'N'})\n",
    "    dataset = dataset.map(lambda x: {\"HasEmojisYN\": 'Y' if has_emojis(x['post']) else 'N'})\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T20:59:41.425042800Z",
     "start_time": "2023-11-15T20:59:41.420411400Z"
    }
   },
   "id": "6de395c49b31b9ad"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/112900 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12c66aefcc8840c1b5e948c1ef01cf2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/112900 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "267b18fb25eb4d57a69ca2ecdc88034c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/17501 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fbd109c31c94249a7875bf9f66ac27b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/17501 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3816bda74fb432295ec6bc8fb29791c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112900, 10328)\n"
     ]
    }
   ],
   "source": [
    "train_data = apply_custom_features(train_data)\n",
    "test_data = apply_custom_features(test_data)\n",
    "\n",
    "# Separate the features and labels for training and testing data\n",
    "labels_tr = train_data[\"offensiveYN\"]\n",
    "data_tr = train_data.remove_columns(\"offensiveYN\")\n",
    "labels_te = test_data[\"offensiveYN\"]\n",
    "data_te = test_data.remove_columns(\"offensiveYN\")\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "data_tr = data_tr.to_pandas()\n",
    "data_te = data_te.to_pandas()\n",
    "\n",
    "# Step 2: Preprocess the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=10, token_pattern=r'[a-zA-Z]+')\n",
    "X_train = tfidf_vectorizer.fit_transform(data_tr['post'])\n",
    "X_test = tfidf_vectorizer.transform(data_te['post'])\n",
    "\n",
    "print(X_train.shape)  # Check the shape of X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:00:15.121978500Z",
     "start_time": "2023-11-15T20:59:41.425042800Z"
    }
   },
   "id": "9d1576d8e46e2a92"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Combine text features and additional features\n",
    "data_tr['HasLinksYN'] = data_tr['HasLinksYN'].map({'N': 0, 'Y': 1})\n",
    "data_tr['HasEmojisYN'] = data_tr['HasEmojisYN'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "data_te['HasLinksYN'] = data_te['HasLinksYN'].map({'N': 0, 'Y': 1})\n",
    "data_te['HasEmojisYN'] = data_te['HasEmojisYN'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "# Select only the numeric columns for converting to sparse matrix\n",
    "numeric_columns_tr = ['HasLinksYN', 'HasEmojisYN'] \n",
    "numeric_columns_te = ['HasLinksYN', 'HasEmojisYN']\n",
    "\n",
    "# Convert additional features to sparse matrix\n",
    "data_tr_sparse = csr_matrix(data_tr[numeric_columns_tr].values)\n",
    "data_te_sparse = csr_matrix(data_te[numeric_columns_te].values)\n",
    "\n",
    "# Combine text features and additional features\n",
    "X_combined_train = hstack([X_train, data_tr_sparse], format='csr')\n",
    "X_combined_test = hstack([X_test, data_te_sparse], format='csr')\n",
    "\n",
    "# Step 4: Prepare labels\n",
    "y_train = labels_tr\n",
    "y_test = labels_te\n",
    "\n",
    "# # Define the parameter grid to search for the best 'max_depth'\n",
    "# param_grid = {'max_depth': range(1, 21)}  # Searching from 1 to 20\n",
    "# \n",
    "# # Initialize the decision tree classifier\n",
    "# dtree = DecisionTreeClassifier(random_state=42)\n",
    "#\n",
    "# # Initialize GridSearchCV with cross-validation\n",
    "# grid_search = GridSearchCV(dtree, param_grid, cv=5, scoring='accuracy')\n",
    "#\n",
    "# # Fit GridSearchCV on the training data\n",
    "# grid_search.fit(X_combined_train, y_train)\n",
    "#\n",
    "# # Print the best parameter and the corresponding score from the training (cross-validation)\n",
    "# print(f\"Best Parameter from training: {grid_search.best_params_}\")\n",
    "# print(f\"Best Score from training: {grid_search.best_score_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:00:15.177053500Z",
     "start_time": "2023-11-15T21:00:15.122979400Z"
    }
   },
   "id": "830ca925210a9c4f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.6480201131363922\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.02      0.03      0.02       232\n",
      "         0.0       0.54      0.69      0.61      5500\n",
      "         0.5       0.10      0.06      0.07      1230\n",
      "         1.0       0.78      0.71      0.75     10539\n",
      "\n",
      "    accuracy                           0.65     17501\n",
      "   macro avg       0.36      0.37      0.36     17501\n",
      "weighted avg       0.65      0.65      0.64     17501\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(X_combined_train, y_train)\n",
    "\n",
    "# Step 6: Make Predictions on the test set\n",
    "y_pred = clf.predict(X_combined_test)\n",
    "\n",
    "# Step 7: Evaluate the Model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred)\n",
    "report_dt = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(report_dt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:01:09.189593200Z",
     "start_time": "2023-11-15T21:00:15.152750500Z"
    }
   },
   "id": "f875dbbdaefca06b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.7566996171647334\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00       232\n",
      "         0.0       0.67      0.75      0.71      5500\n",
      "         0.5       0.00      0.00      0.00      1230\n",
      "         1.0       0.81      0.86      0.83     10539\n",
      "\n",
      "    accuracy                           0.76     17501\n",
      "   macro avg       0.37      0.40      0.39     17501\n",
      "weighted avg       0.70      0.76      0.72     17501\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the Naive Bayes Classifier\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_combined_train, y_train)\n",
    "\n",
    "# Step 9: Make Predictions on the test set with Naive Bayes\n",
    "y_pred_nb = nb_clf.predict(X_combined_test)\n",
    "\n",
    "# Step 10: Evaluate the Naive Bayes Model\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "report_nb = classification_report(y_test, y_pred_nb, zero_division=0)\n",
    "\n",
    "print(\"\\nNaive Bayes Results:\")\n",
    "print(f\"Accuracy: {accuracy_nb}\")\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(report_nb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:01:09.317681700Z",
     "start_time": "2023-11-15T21:01:09.186594800Z"
    }
   },
   "id": "12cc9f9cd5997b9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-layer Perceptron Results\n",
      "Accuracy: 0.6984743728929775\n",
      "\n",
      "Multi-layer Perceptron Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00       232\n",
      "         0.0       0.56      0.78      0.65      5500\n",
      "         0.5       0.00      0.00      0.00      1230\n",
      "         1.0       0.81      0.75      0.78     10539\n",
      "\n",
      "    accuracy                           0.70     17501\n",
      "   macro avg       0.34      0.38      0.36     17501\n",
      "weighted avg       0.66      0.70      0.67     17501\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features before feeding them into MLP\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#MLP Hyperparameters\n",
    "MLPlearn = 0.01\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "trunc = svd.fit_transform(X_train_scaled)\n",
    "trunc_test = svd.transform(X_test_scaled)\n",
    "\n",
    "# Train the Multi-layer Perceptron Classifier\n",
    "mlp_clf = MLPClassifier(random_state=1, activation='relu', max_iter=300, learning_rate='adaptive', learning_rate_init=MLPlearn)\n",
    "mlp_clf.fit(trunc, y_train)\n",
    "\n",
    "# Make Predictions on the test set with MLP\n",
    "y_pred_mlp = mlp_clf.predict(trunc_test)\n",
    "\n",
    "# Evaluate the MLP Model\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "report_mlp = classification_report(y_test, y_pred_mlp, zero_division=0)\n",
    "\n",
    "print(\"\\nMulti-layer Perceptron Results\")\n",
    "print(f\"Accuracy: {accuracy_mlp}\")\n",
    "print(\"\\nMulti-layer Perceptron Classification Report:\")\n",
    "print(report_mlp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:01:23.668521300Z",
     "start_time": "2023-11-15T21:01:09.316680100Z"
    }
   },
   "id": "e14eb8d0f41fdbc3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results\n",
      "Accuracy: 0.7753842637563568\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.40      0.01      0.02       232\n",
      "         0.0       0.68      0.81      0.74      5500\n",
      "         0.5       0.18      0.01      0.01      1230\n",
      "         1.0       0.84      0.86      0.85     10539\n",
      "\n",
      "    accuracy                           0.78     17501\n",
      "   macro avg       0.52      0.42      0.40     17501\n",
      "weighted avg       0.74      0.78      0.75     17501\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression Classifier\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions on the test set with Logistic Regression\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the Logistic Regression Model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "report_lr = classification_report(y_test, y_pred_lr, zero_division=0)\n",
    "\n",
    "print(\"\\nLogistic Regression Results\")\n",
    "print(f\"Accuracy: {accuracy_lr}\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(report_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:01:32.301140500Z",
     "start_time": "2023-11-15T21:01:23.664520800Z"
    }
   },
   "id": "967c17003d9fe4de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
